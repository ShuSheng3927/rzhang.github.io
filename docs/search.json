[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rui-Yang Zhang",
    "section": "",
    "text": "I am currently in the first year of STOR-i CDT at Lancaster University. My PhD project looks at Bayesian experiment design for ocean currents predictions, and is in collaboration with TIDE. My supervisors are Henry Moss and David Leslie at Lancaster, as well as Lachlan Astfalck and Edward Cripps at UWA.\nPreviously, I did BSc Mathematics and Statistical Science at UCL where I was mentored by Sam Livingstone and received a Royal Statistical Society Award.\nI am broadly interested in computational statistics and machine learning methodologies, and their applications in science and healthcare. See here for more information.\nI am currently organising the Lancaster AI Reading Group."
  },
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "Notes",
    "section": "",
    "text": "Computational Statistics\n\nBasic Markov chain Monte Carlo Method\nPDMP and MCMC\nGeometric Ergodicities of Langevin and Barker Algorithms\nIntroduction to Sequential Monte Carlo\n\n\n\nMachine Learning\n\nWasserstein Gradient Flow\nIntroduction to Gaussian Processes\nIntroduction to Bayesian Optimisation\n\n\n\nBiostatistics\n\nMultiple Testing Problem\nResponse-Adaptive Randomisation (code1) (code2)\n\n\n\nCourse notes\n\nSpectral Theory\nProbability Theory\n\n\n\nUncategorised\n\nUnivariate Extreme Value Modelling"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "I am broadly interested in computational statistics and machine learning methodologies, and their applications in scientific and health-related disciplines. In particular, I am interested in (1) developing methodologies with strong relevance to applications, and (2) advancing our understandings of the underlying mechanisms behind existing, commonly used algorithms. Below are some of the keywords that interest me:\nCurrently, I am investigating how Bayesian optimisation and active learning, in combination with physics-informed Gaussian processes surrogate models, can help engineers and oceanographers to better understand ocean currents and inform their exploration strategies."
  },
  {
    "objectID": "research.html#publication",
    "href": "research.html#publication",
    "title": "Research",
    "section": "Publication",
    "text": "Publication\nGoogle Scholar\n\nPreprint\n\nLivingstone, S., Nüsken, N., Vasdekis, G., & Zhang, R. Y. (2024). Skew-symmetric schemes for stochastic differential equations with non-Lipschitz drift: an unadjusted Barker algorithm. [arxiv] (submitted)"
  },
  {
    "objectID": "research.html#links",
    "href": "research.html#links",
    "title": "Resources",
    "section": "",
    "text": "BibTeX Tidy"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Lancaster CSML\nLancaster AI Reading Group\nUCL Fundamentals of Statistical Machine Learning\nGP Seminar Series\n\n\n\n\n\nProb_AI Hub\nSTOR-i\nTIDE"
  },
  {
    "objectID": "resources.html#links",
    "href": "resources.html#links",
    "title": "Resources",
    "section": "Links",
    "text": "Links\n\nLaTeX Tools\n\nBibTeX Tidy, tidy up .bib files\nLaTeX Table Generator, make a table as if you are in excel then convert to LaTeX codes\nQuiver, draw commuative diagrams using drags and pulls\n\n\n\nStatistics / ML\n\nMCMC Interactive Gallery, live demo of common MCMC algorithms on interesting targets\nGP Interactive Gallery, interactive visualisation of GP, very neat!\n\n\n\nHobbies\n\nWikiArt, online archive for art work\nXu Bing 徐冰, contemporary artist. Square Word Calligraphy, Book from the Sky, Background Story, Phoenix\nZao Wou-Ki 趙無極, painter. Le Soleil Rouge.\nLucien Freud, painter. portraits, self portraits\nFrancis Bacon, painter. Popes, Three Studies for Figures at the Base of a Crucifixion, self portraits\nEdward Hopper, painter. House by the railroad, office at night\nHaruki Murakami 村上 春樹, novelist. Hear the Wind Sing, Dance Dance Dance, The Wind-Up Bird Chronicle, After Dark, Men Without Women, What I Talk About When I Talk About Running, Novelist as a Vocation\nAng Lee 李安, director. Father Trilogy\nWoody Allen, director. Annie Hall, Match point, Midnight in Paris\nI. M. Pei 貝聿銘, architect. Pyramid, Suzhou Museum, Bank of China Tower\nXiang Biao 项飙, sociologist. Global Body Shopping, Self as Methods\nChen Jia-Ying 陈嘉映, philosopher. 哲学·科学·常识, 何为良好生活, 走出唯一真理观"
  },
  {
    "objectID": "resources.html#academic-groups-organisations",
    "href": "resources.html#academic-groups-organisations",
    "title": "Resources",
    "section": "",
    "text": "Lancaster CSML\nLancaster AI Reading Group\nUCL Fundamentals of Statistical Machine Learning\nGP Seminar Series\n\n\n\n\n\nProb_AI Hub\nSTOR-i\nTIDE"
  },
  {
    "objectID": "resources.html#academic-groups-and-organisations",
    "href": "resources.html#academic-groups-and-organisations",
    "title": "Resources",
    "section": "",
    "text": "Lancaster CSML\nLancaster AI Reading Group\nUCL Fundamentals of Statistical Machine Learning\nGP Seminar Series\n\n\n\n\n\nProb_AI Hub\nSTOR-i\nTIDE"
  },
  {
    "objectID": "enlightenment_gallery.html",
    "href": "enlightenment_gallery.html",
    "title": "Rui-Yang Zhang",
    "section": "",
    "text": "It was early 2021 when I first visited the British Museum. I was in my first year of undergraduate at UCL, and it was the middle stage of covid where lockdowns were on and off. It was a confusing time to most, and especially to me, as I was in between the discomfort of moving to a new country in a foreign continent, the uncertainties in an increasingly precarious world, and the urge for a sensible life plan.\nMy first visit was on a cloudy afternoon, rather typical weather for London during that time of the year. Few visitors were in the museum, and the ones there were subconsciously maintaining some distance from each other. The enlightenment gallery was the last stop of my visit that time, and I was exhausted, mentally and physically, from walking nonstop for two hours and seeing countless artefacts.\nThe curtains of the gallery were loosely pulled down, allowing the afternoon sun to permeate through. The long hallway - with seemingly endless shelves of books extending from the floor to the ceiling on the two sides- was bright enough to display its overwhelming wealth and dim enough to remain mysteriously noble. It was stunning. I walked towards the middle of the gallery and sat on a bench. Mesmerised by the weight of intellectual history.\nSince then, I have been back to the museum and that same enlightenment gallery numerous times, yet I could never recreate that same astonishment. Maybe I would never be in that same mental space, for better or for worse, and maybe the museum would never be that empty again, to leave me alone with the artefacts and the history."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Reading Notes: Environmental sensor placement with convolutional Gaussian neural processes\n\n\n\n\n\n\n\nGaussian Process\n\n\nExperiment Design\n\n\nReading Notes\n\n\n\n\nReading Notes on Environmental sensor placement with convolutional Gaussian neural processes\n\n\n\n\n\n\nSep 30, 2024\n\n\nRui-Yang Zhang\n\n\n\n\n\n\n  \n\n\n\n\nReading Notes: Pre-trained Gaussian Processes for Bayesian Optimization\n\n\n\n\n\n\n\nBayesian Optimisation\n\n\nGaussian Process\n\n\nActive Learning\n\n\nExperiment Design\n\n\nReading Notes\n\n\n\n\nReading Notes on Pre-trained Gaussian Processes for Bayesian Optimization\n\n\n\n\n\n\nSep 29, 2024\n\n\nRui-Yang Zhang\n\n\n\n\n\n\n  \n\n\n\n\nWhy Should We Care About Gradient Flows?\n\n\n\n\n\n\n\nGradient Flows\n\n\n\n\nBlog post on gradient flows in Euclidean and Wasserstein spaces.\n\n\n\n\n\n\nSep 13, 2024\n\n\nRui-Yang Zhang, Christopher Nemeth\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-09-29-test/index.html",
    "href": "posts/2024-09-29-test/index.html",
    "title": "Reading Notes: Pre-trained Gaussian Processes for Bayesian Optimization",
    "section": "",
    "text": "Paper Link: https://www.jmlr.org/papers/volume25/23-0269/23-0269.pdf"
  },
  {
    "objectID": "posts/2024-09-29-test/index.html#motivation",
    "href": "posts/2024-09-29-test/index.html#motivation",
    "title": "Reading Notes: Pre-trained Gaussian Processes for Bayesian Optimization",
    "section": "Motivation",
    "text": "Motivation\nBO relies on surrogate models (often chosen to be GPs). A GP is specified by a kernel (and a mean sometimes), which reflects our prior knowledge about the black box function of interest. In addition, since we often do not have too many observations being queried from the black box function, the outcome will be sensitive to prior choices.\nIn this paper, the authors are motivated by BO in the context of hyperparameter tuning of large-scale ML models, where the common choices of the kernel (e.g. SE, Matern) are often unrealistic. In many settings where a GP prior is decided, a lot of domain / contextual knowledge is first gathered to make a sensible guess at how the function might look like (e.g. periodicities, spectral properties, smoothness). Such knowledge is often missing in the ML model hyperparameter tuning case.\nTo resolve this issue, the authors proposed a “transfer learning” / “information borrowing” / “pre-training” / “meta-learning” approach to turning existing final GP models from similar large-scale ML models’ hyperparameter tuning tasks into priors for the next task with a slightly different ML model. The new approach is called the HyperBO."
  },
  {
    "objectID": "posts/2024-09-29-test/index.html#methods",
    "href": "posts/2024-09-29-test/index.html#methods",
    "title": "Reading Notes: Pre-trained Gaussian Processes for Bayesian Optimization",
    "section": "Methods",
    "text": "Methods\nThe key component of HyperBO is the construction of a pre-trained prior GP. Everything else goes like the standard BO loops. We denote \\(f\\)as our current black-box function that we wish to run BO on. We have past knowledge about the functions \\(f_1, f_2, \\ldots, f_N\\) with observation datasets \\(D_1, D_2, \\ldots, D_N\\) each consists of \\(M\\) location-value pairs of the corresponding function.\nThe main assumption (Assumption 1 of paper) made in this paper, which is essential for the construction of our pre-trained prior, is that all the previously explored functions as well as our current function are i.i.d. draws from a common meta GP, i.e. \\(f_1, f_2, \\ldots, f_N, f \\sim \\mathcal{GP}(\\mu^*, k^*)\\). The other assumption (Assumption 2), which is more minor, is that the observations are all noisy with noise being additive, centred, Gaussian, and of unknown constant variance \\(\\sigma_*^2\\).\nUnder these two assumptions, we are ready to explain how the pre-trained prior is obtained. We construct a loss function \\(\\mathcal{L}\\) of the form\n\\[\n\\mathcal{L}(\\mu, k, \\sigma^2)=\\text{KL}\\left(\\mathcal{GP}_{\\sigma_*^2}(\\mu^*, k^*), \\mathcal{GP}_{\\sigma^2}(\\mu, k)\\right)\n\\]\nwhere the subscripts \\(\\sigma^2, \\sigma_*^2\\) denote the variances of the observation noise, and this is used to be optimised to obtain our estimations of the hyperparameters of our pre-trained GP. The equation above corresponds to Equation (1) in the paper with slightly adjusted notations.\nThe paper proposed two ways - KL-based and likelihood-based - to rewrite the above loss function to make it more computationally tractable."
  },
  {
    "objectID": "posts/2024-09-29-test/index.html#discussions",
    "href": "posts/2024-09-29-test/index.html#discussions",
    "title": "Reading Notes: Pre-trained Gaussian Processes for Bayesian Optimization",
    "section": "Discussions",
    "text": "Discussions\nThe approach proposed in the paper can be (at least intuitively) related to the empirical Bayes approach of inference, where the prior is obtained using some sort of MLEs of the parameters using the observations. Here, the prior GP is modelled as a sample from the meta GP \\(\\mathcal{GP}(\\mu^*, k^*)\\) with hyperparameters estimated using existing data of previous BO tasks.\nIt could also be beneficial to consider the potential link between this work and the generalised Bayes ideas (e.g. A General Framework for Updating Belief Distributions and An Optimization-centric View on Bayes’ Rule). Slightly more concretely, maybe those works could provide a different way of pre-training our GP prior given past observations.\nThe method proposed in this paper is heavily dependent on the problem setup, especially the Assumption 1 of the paper. This assumption is sensible in many contexts, such as the hyperparameter tuning examples mentioned in the paper, but it is certainly not generally applicable."
  },
  {
    "objectID": "posts/2024-09-29-pretrain-GP-BO/index.html",
    "href": "posts/2024-09-29-pretrain-GP-BO/index.html",
    "title": "Reading Notes: Pre-trained Gaussian Processes for Bayesian Optimization",
    "section": "",
    "text": "Paper Link: https://www.jmlr.org/papers/volume25/23-0269/23-0269.pdf"
  },
  {
    "objectID": "posts/2024-09-29-pretrain-GP-BO/index.html#motivation",
    "href": "posts/2024-09-29-pretrain-GP-BO/index.html#motivation",
    "title": "Reading Notes: Pre-trained Gaussian Processes for Bayesian Optimization",
    "section": "Motivation",
    "text": "Motivation\nBO relies on surrogate models (often chosen to be GPs). A GP is specified by a kernel (and a mean sometimes), which reflects our prior knowledge about the black box function of interest. In addition, since we often do not have too many observations being queried from the black box function, the outcome will be sensitive to prior choices.\nIn this paper, the authors are motivated by BO in the context of hyperparameter tuning of large-scale ML models, where the common choices of the kernel (e.g. SE, Matern) are often unrealistic. In many settings where a GP prior is decided, a lot of domain / contextual knowledge is first gathered to make a sensible guess at how the function might look like (e.g. periodicities, spectral properties, smoothness). Such knowledge is often missing in the ML model hyperparameter tuning case.\nTo resolve this issue, the authors proposed a “transfer learning” / “information borrowing” / “pre-training” / “meta-learning” approach to turning existing final GP models from similar large-scale ML models’ hyperparameter tuning tasks into priors for the next task with a slightly different ML model. The new approach is called the HyperBO."
  },
  {
    "objectID": "posts/2024-09-29-pretrain-GP-BO/index.html#methods",
    "href": "posts/2024-09-29-pretrain-GP-BO/index.html#methods",
    "title": "Reading Notes: Pre-trained Gaussian Processes for Bayesian Optimization",
    "section": "Methods",
    "text": "Methods\nThe key component of HyperBO is the construction of a pre-trained prior GP. Everything else goes like the standard BO loops. We denote \\(f\\)as our current black-box function that we wish to run BO on. We have past knowledge about the functions \\(f_1, f_2, \\ldots, f_N\\) with observation datasets \\(D_1, D_2, \\ldots, D_N\\) each consists of \\(M\\) location-value pairs of the corresponding function.\nThe main assumption (Assumption 1 of paper) made in this paper, which is essential for the construction of our pre-trained prior, is that all the previously explored functions as well as our current function are i.i.d. draws from a common meta GP, i.e. \\(f_1, f_2, \\ldots, f_N, f \\sim \\mathcal{GP}(\\mu^*, k^*)\\). The other assumption (Assumption 2), which is more minor, is that the observations are all noisy with noise being additive, centred, Gaussian, and of unknown constant variance \\(\\sigma_*^2\\).\nUnder these two assumptions, we are ready to explain how the pre-trained prior is obtained. We construct a loss function \\(\\mathcal{L}\\) of the form\n\\[\n\\mathcal{L}(\\mu, k, \\sigma^2)=\\text{KL}\\left(\\mathcal{GP}_{\\sigma_*^2}(\\mu^*, k^*), \\mathcal{GP}_{\\sigma^2}(\\mu, k)\\right)\n\\]\nwhere the subscripts \\(\\sigma^2, \\sigma_*^2\\) denote the variances of the observation noise, and this is used to be optimised to obtain our estimations of the hyperparameters of our pre-trained GP. The equation above corresponds to Equation (1) in the paper with slightly adjusted notations.\nThe paper proposed two ways - KL-based and likelihood-based - to rewrite the above loss function to make it more computationally tractable.\n\n\n\nIllustration of the Pre-Train GP"
  },
  {
    "objectID": "posts/2024-09-29-pretrain-GP-BO/index.html#discussions",
    "href": "posts/2024-09-29-pretrain-GP-BO/index.html#discussions",
    "title": "Reading Notes: Pre-trained Gaussian Processes for Bayesian Optimization",
    "section": "Discussions",
    "text": "Discussions\nThe approach proposed in the paper can be (at least intuitively) related to the empirical Bayes approach of inference, where the prior is obtained using some sort of MLEs of the parameters using the observations. Here, the prior GP is modelled as a sample from the meta GP \\(\\mathcal{GP}(\\mu^*, k^*)\\) with hyperparameters estimated using existing data of previous BO tasks.\nIt could also be beneficial to consider the potential link between this work and the generalised Bayes ideas (e.g. A General Framework for Updating Belief Distributions and An Optimization-centric View on Bayes’ Rule). Slightly more concretely, maybe those works could provide a different way of pre-training our GP prior given past observations.\nThe method proposed in this paper is heavily dependent on the problem setup, especially the Assumption 1 of the paper. This assumption is sensible in many contexts, such as the hyperparameter tuning examples mentioned in the paper, but it is certainly not generally applicable."
  },
  {
    "objectID": "posts/2024-09-13-WGF/index.html",
    "href": "posts/2024-09-13-WGF/index.html",
    "title": "Why Should We Care About Gradient Flows?",
    "section": "",
    "text": "Optimisation is a fundamental task in modern-day statistics and machine learning. A large set of problems in machine learning and statistics can be easily phrased as an optimisation problem - given some objective function \\(f\\) defined on a domain \\(\\mathcal{X}\\), we wish to find a point \\(x \\in \\mathcal{X}\\) that minimises \\(f\\) (or maximises \\(-f\\)). Sometimes, we do not even need to find the global minimum of \\(f\\), and a sufficiently close local minimum would be good too."
  },
  {
    "objectID": "posts/2024-09-13-WGF/index.html#gradient-flows-in-the-euclidean-space",
    "href": "posts/2024-09-13-WGF/index.html#gradient-flows-in-the-euclidean-space",
    "title": "Why Should We Care About Gradient Flows?",
    "section": "Gradient Flows in the Euclidean Space",
    "text": "Gradient Flows in the Euclidean Space\nA common optimisation algorithm is the gradient descent. If our objective function \\(f\\) defined on the Euclidean space \\(\\mathbb{R}^d\\) is continuous and we can compute its gradient \\(\\nabla f\\), then, the gradient descent algorithm will iteratively apply the following update\n\\[\nx_{n+1} = x_n - h \\nabla f(x_n)\n\\]\nuntil we converge or reach a termination point. The parameter \\(h&gt;0\\) above is the step size of our algorithm, often referred to as a learning rate and it is a tuning parameter of the gradient descent algorithm. When we set \\(h\\) to be very small, and let it tend to zero, we would convert the above discrete-in-time algorithm into a continuous-in-time algorithm, described as\n\\[\n\\frac{\\mathrm{d}}{\\mathrm{d}t} x_t = -\\nabla f(x_t)\n\\]\nwhere we use \\(t\\) instead of \\(n\\) to denote the time index as we are in continuous time rather than discrete time. Notice that for the above ordinary differential equation (ODE), after an Euler discretisation (of time), will become the gradient descent algorithm. The ODE is known as the gradient flow (in Euclidean space), and we can show that various frequently used algorithms can be interpreted as different discretisations of the gradient flow. For example, an implicit Euler discretisation of the gradient flow gives us the proximal point algorithm.\nOne can certainly see the conceptual benefit of considering gradient flow for understanding discrete-in-time optimisation algorithms - we suddenly have a simple, elegant mental picture of the limiting case of these procedures. However, rather unfortunately, the gradient flow in Euclidean space could not help us that much more than that. Often in theoretical analysis of iterative algorithms, we are interested in the convergence rate of these algorithms to some target value, and in the cases where approximations happen in the algorithms, we are interested in capturing the errors induced. Because of the discretisation in time, we could not translate many of the theories about gradient flow in Euclidean space into their discrete-in-time counterparts. This is the main reason why although gradient flows are extremely natural and tempting to investigate, they have not been considered as much, until very recently."
  },
  {
    "objectID": "posts/2024-09-13-WGF/index.html#the-langevin-diffusion",
    "href": "posts/2024-09-13-WGF/index.html#the-langevin-diffusion",
    "title": "Why Should We Care About Gradient Flows?",
    "section": "The Langevin Diffusion",
    "text": "The Langevin Diffusion\nA major breakthrough, at least from a theoretical perspective, happened with Jordan, Kinderlehrer & Otto’s 1998 paper The Variational Formulation of the Fokker-Planck Equation. In there, the authors made an explicit connection between the Langevin diffusion, a particular type of Stochastic Differential Equation (SDE) with very nice equilibrium properties, and a gradient flow in the space of probability distributions. The Langevin diffusion can be characterised by the SDE\n\\[\n\\mathrm{d}X_t = \\nabla \\log \\pi(X_t) \\mathrm{d}t + \\sqrt{2}\\mathrm{d}B_t\n\\]\nwhere \\(\\{B_t\\}\\) is a Brownian motion and \\(\\pi\\) is the equilibrium distribution of the process, and it could also be characterised by the Fokker-Planck equation\n\\[\n\\partial_t p_t(x) = \\text{div} \\left( p_t(x) \\nabla \\log \\frac{p_t(x)}{\\pi(x)} \\right)\n\\]\nwhere \\(p_t(x)\\) is the probability distribution of \\(X_t\\). Naively, one can think about the two characterisations of the Langevin diffusion as a state space version and a distribution space version of the same motion.\nSo, the paper of JKO1998 established that the Fokker-Planck equation of the Langevin diffusion is equivalent to a gradient flow in the Wasserstein space with the objective function being the KL divergence \\(f(\\cdot) = \\text{KL}(\\cdot \\| \\pi)\\) where\n\\[\n\\text{KL}(p\\| q) := \\int p(x) \\log[p(x) / q(x)] dx = \\mathbb{E}_{X \\sim p} [\\log ( p(X)/q(X)) ].\n\\]\nIntuitively, what this connection tells us is that the particles following a Langevin diffusion are moving - in the steepest direction - towards their equilibrium distribution.\nAs an example, let’s assume that our target distribution of interest \\(p\\) is a Gaussian \\(\\mathcal{N}(0,1)\\) and particles are represented by the distribution \\(q\\). As seen in the following movie, we can use the Wasserstein gradient flow of KL divergence to sequentially evolve \\(q\\) and minimise the KL divergence.\n (Thanks to Louis Sharrock for creating this movie)\nThis result seems neat, but what is so special about this Langevin diffusion? It turns out that the Langevin diffusion is rather fundamental in sampling algorithms for computational statistics."
  },
  {
    "objectID": "posts/2024-09-13-WGF/index.html#monte-carlo-sampling",
    "href": "posts/2024-09-13-WGF/index.html#monte-carlo-sampling",
    "title": "Why Should We Care About Gradient Flows?",
    "section": "Monte Carlo Sampling",
    "text": "Monte Carlo Sampling\nIn statistics, especially in Bayesian statistics, we would often run into the problem of having a complicated probability distribution that we wish to compute expectations of, such as in the case of computing the posterior mean of a parameter of interest. If the distribution is complex and we cannot analytically evaluate our expectations of interest, then we often rely on using (independent) samples from the distribution to form an empirical approximation of the distribution. To be more precise, if we have a target probability distribution \\(\\pi\\), we will get a sequence of independent samples \\(X_1, X_2, \\ldots, X_n \\sim \\pi\\) and we have\n\\[\n\\pi(x) \\approx \\frac{1}{n} \\sum_{k=1}^n 1_{X_k}(x)\n\\]\nwhere \\(1_{X_k}(x)\\) is the indicator function that takes the value 1 when \\(x = X_k\\) and zero otherwise. This is the Monte Carlo method, and it can be shown that under weak conditions of the target distribution \\(\\pi\\), the empirical distribution converges to \\(\\pi\\) at a rate of \\(O(1/\\sqrt{n})\\) for \\(n\\) Monte Carlo samples. The only problem with the Monte Carlo method is, how do we get those samples? As alluded slightly from the Langevin diffusion, since we can set the equilibrium distribution of a Langevin diffusion to (almost) any target distribution and the process will converge to it after running for a while, we can just start the SDE at some point and run it for long enough so it hits the equilibrium, and use the trajectories afterwards as samples from the target distribution.\nImmediately, we would ask - how exactly do we simulate a continuous-in-time SDE? The simplest solution is to use the Euler-Maruyama scheme and obtain discretisations using the following iterative procedure\n\\[\nX_{(n+1)h} = X_{nh} + h \\nabla \\log \\pi(X_{nh})+\\sqrt{2h} \\xi\n\\]\nwhere \\(\\xi \\sim N(0,1)\\). This gives us the unadjusted Langevin algorithm (ULA), also known as the Langevin Monte Carlo (LMC) algorithm in the machine learning literature.\nSince this is a discretisation, it introduces some numerical errors (the precise reason for the errors will be explained in a bit) and by using ULA we will not obtain exact samples from the target distribution \\(\\pi\\). For sufficiently small \\(h\\), the error would be tolerable. We could also do smart things such as Metropolis adjustments to remove the error, and we would recover the Metropolis Adjusted Langevin Algorithm (MALA) which is a staple of the Markov chain Monte Carlo (MCMC) algorithms for computational statistics. More thorough discussions on MCMC algorithms can be found in textbooks such as Monte Carlo Statistical Methods by Robert & Casella, or the recent Scalable Monte Carlo for Bayesian Learning by Fearnhead, Nemeth, Oates & Sherlock. One could also find a more detailed theoretical study of ULA in Roberts & Tweedie’s 1996 paper Exponential Convergence of Langevin Distributions and their Discrete Approximations."
  },
  {
    "objectID": "posts/2024-09-13-WGF/index.html#wasserstein-gradient-flow---a-bridge-between-sampling-and-optimisation",
    "href": "posts/2024-09-13-WGF/index.html#wasserstein-gradient-flow---a-bridge-between-sampling-and-optimisation",
    "title": "Why Should We Care About Gradient Flows?",
    "section": "Wasserstein Gradient Flow - a Bridge between Sampling and Optimisation",
    "text": "Wasserstein Gradient Flow - a Bridge between Sampling and Optimisation\nSo far, we have learnt that the Langevin diffusion can be viewed as a gradient flow, and the discrete-in-time version of the Langevin diffusion allows us to draw samples from a target distribution. It turns out that we can also interpret the discrete Langevin diffusion of the LMC as a discrete-in-time approximation of the corresponding gradient flow in the space of probability distributions (to be more precise, the Wasserstein space, so we would often call this type of gradient flow a Wasserstein gradient flow).\nIn the 2018 paper Sampling as Optimization in the Space of Measures by Wibisono, the author pointed out that the LMC as an Euler-Maruyama discretisation of the Langevin diffusion can be viewed as a forward-flow splitting discretisation of the Wasserstein gradient flow with the objective function being the KL divergence. The forward-flow splitting scheme is a way to discretise time by doing half a step of forward discretisation, and half a step of flow discretisation, for each full step of the iteration. The expression of the two discretisations is slightly involved to describe in the space of probability distributions, but if we translate them into the state space, it is simply\n\\[\n\\text{(forward)} \\ X_{(n+1/2)h} = X_{nh} + h \\nabla \\log \\pi(X_{nh}),\n\\] \\[\n\\text{(flow)} \\ X_{(n+1)h} = X_{(n+1/2)h} + \\sqrt{2h} \\xi\n\\] with \\(\\xi \\sim N(0,1)\\), which combines to give us the full LMC update. Another observation in Wibisono (2018) is that, if we swap the flow step with a backward discretisation step, we would be able to cancel the error of discretising the Langevin diffusion. Unfortunately, the backward step is not implementable in general. Nevertheless, this paper provides us with the very important information that there exists a hidden connection between sampling (using LMC) and optimisation (using gradient flows). A bridge between the two areas has been formally built at this point.\nTo further utilise the power of this connection, Durmus, Majewski & Miasojedow in their 2019 paper Analysis of Langevin Monte Carlo via Convex Optimization provided us with a more explicit characterisation of the error of LMC using convergence analysis of the Wasserstein gradient flow. Unlike in the case of gradient flows in Euclidean space, the theoretical studies of Wasserstein gradient flows can actually be used in the analysis of their discrete-in-time counterparts."
  },
  {
    "objectID": "posts/2024-09-13-WGF/index.html#what-else-can-we-do",
    "href": "posts/2024-09-13-WGF/index.html#what-else-can-we-do",
    "title": "Why Should We Care About Gradient Flows?",
    "section": "What Else Can We Do?",
    "text": "What Else Can We Do?\nAt this point, it should be clear that the connection between sampling and optimisation established using Wasserstein gradient flows is promising and potentially very useful.\nOne immediate area of work is to interpret existing sampling algorithms as gradient flows, and use these realisations to help us better understand the properties of these algorithms. There are already some successful fruits from this branch:\n\nLiu’s 2017 paper Stein Variational Gradient Descent as Gradient Flow interpreted the Stein Variational Gradient Descent algorithm, a powerful sampling algorithm, as a type of gradient flow.\nDuncan, Nüsken & Szpruch’s 2023 paper On the Geometry of Stein Variational Gradient Descent built on the above realisation and showed several convergence results about the algorithm, as well as certain improvements based on such gradient flow analysis.\nNüsken’s 2024 paper Stein Transport for Bayesian Learning proposed a promising new algorithm Stein Transport that extends the Stein Variational Gradient Descent by tweaking the geometry of the Wassterstein gradient flow.\nChopin, Crucinio & Korba’s 2024 paper A connection between Tempering and Entropic Mirror Descent has established that tempering sequential Monte Carlo algorithms can be viewed as a type of discretisation of the gradient flow in the Fisher-Rao geometry.\n\nIn addition, a class of work that could be made possible with this new connection is those that translate algorithmic tricks from one field (say optimisation) to another (say sampling). A very nice example of this thinking is the line of work by Sharrock, Nemeth and coauthors over recent years. A lot of optimisation algorithms involve tuning parameters (also known as learning rates) that have to be manually adjusted, and different specifications of them will sometimes yield very different performance of the algorithms. To tackle the difficulties of tuning such parameters, there is a class of learning-rate-free algorithms that replace the tuning of learning rates with an automatic mechanism. With the help of the connection between sampling and optimisation made by gradient flows, recent work has managed to replace the manually-tuned learning rates of sampling algorithms with automatic, learning-rate-free ones, as shown in the papers such as Coin Sampling: Gradient-Based Bayesian Inference without Learning Rates and Learning Rate Free Sampling in Constrained Domains.\nOverall, gradient flows and related ideas have become a promising tool for investigating theoretical properties of sampling algorithms, and have shown a considerable amount of potential to inspire designs of new sampling algorithms. There remains a vast pool of unanswered questions and possible extensions in this area. More breakthroughs are to be expected from this line of work.\nP.S. A book-length, formal introduction to the material covered above and more can be found in Statistical Optimal Transport by Chewi, Niles-Weed & Rigollet."
  },
  {
    "objectID": "posts/2024-09-30-ConvGNP/index.html",
    "href": "posts/2024-09-30-ConvGNP/index.html",
    "title": "Reading Notes: Environmental sensor placement with convolutional Gaussian neural processes",
    "section": "",
    "text": "Paper Link: https://doi.org/10.1017/eds.2023.22\n## Motivation\nThe object of interest of this paper is the environmental / climate data, and the task of interest is to model them for various downstream tasks such as sequential experiment designs and predictions. The object of interest, climate data, has two key properties: (1) spatiotemporal non-stationarity, and (2) large data volume and high data variability. They will be further explained below. Ultimately, these two properties make the standard probabilistic model of choice - the Gaussian Process - unsuitable and a new model, the Convolutional Gaussian Neural Process (ConvGNP) is proposed in the paper as an alternative.\nClimate variables are non-stationary across time and space due to seasonality and other natural phenomena, so the probabilistic model must capture those characteristics to be sufficiently realistic. The standard Gaussian process could potentially encode them via the careful design of the kernel, which is non-trivial.\nThere is also a large volume of existing climate data, and they could be of very different formats (e.g. satellite images, weather station observations). GP is notoriously unscalable in data size, and the varied formats prevent us from a direct compilation of data since we cannot assume all the available data are numerical and measuring the same thing. This issue of data format variability also exists in other disciplines, such as ecology (e.g. citizen science and integrated population model).\nGiven these constraints of the problem, we need a model that scales better with data size and can learn non-stationarity more automatically, which motivates the introduction of ConvGNP."
  },
  {
    "objectID": "posts/2024-09-30-ConvGNP/index.html#model-setup",
    "href": "posts/2024-09-30-ConvGNP/index.html#model-setup",
    "title": "Reading Notes: Environmental sensor placement with convolutional Gaussian neural processes",
    "section": "Model Setup",
    "text": "Model Setup\nThe model is trained as a regression with covariates. The base regression is an input (region of consideration) and output (environmental variable of interest) assisted by covariates / contexts (from other weather observations). The result of a fitted model is a map \\(\\pi\\) that takes a possible input along with its covariate values and returns a prediction of the output value.\nThe above is extremely high-level and overly simplistic. The overall map \\(\\pi\\) of ConvGNP is constructed as a Neural Net with the following structure:\n\\[\n\\text{Context Set }C \\to \\textbf{SetConv} \\longrightarrow \\textbf{U-Net} \\longrightarrow \\begin{matrix} \\textbf{Multilayer} \\\\ \\textbf{Perceptron} \\end{matrix}\\to \\begin{bmatrix} \\text{mean vector } f\\\\ \\text{covariance matrix }g \\end{bmatrix}\n\\]\nwhere the bold texts refer to the NN architecture and the standard texts refer to the inputs (the context set includes both the input location and the associated covariate values) and outputs (a mean vector and covariance matrix used for a overall multivariate Gaussian output).\nThe \\(\\textbf{SetConv}\\) layer fuses the various formats of data together on a regular grid that is enabled by interpolations so missing data and irregularly gridded data can be understood. The \\(\\textbf{U-Net}\\) produces a representation of the context set, like learning the latent variable structures. The \\(\\textbf{Multilayer Perceptron}\\) takes in the representations and outputs the mean vector and covariance matrix used by a multivariate Gaussian distribution to support a probabilistic outcome. Details about the NN architecture are omitted here.\nEssentially, ConvGNP uses an NN to ingest a large volume of data and outputs a predictive multivariate Gaussian distribution - combining the processing power and scale of NN and the uncertainty quantification of a GP.\nTo get a rough sense of the speed and the amount of data ConvGNP is capable of, here is a footnote from the paper.\n\nOur ConvGNP (with 4.16 M parameters) takes 0.88 s to process a total of 100,000 context points (21,600 temperature points and 78,400 gridded auxiliary points) and predict over 100,000 target points on a 16 GB NVIDIA A4 GPU using TensorFlow’s eager mode."
  },
  {
    "objectID": "posts/2024-09-30-ConvGNP/index.html#experiment-design",
    "href": "posts/2024-09-30-ConvGNP/index.html#experiment-design",
    "title": "Reading Notes: Environmental sensor placement with convolutional Gaussian neural processes",
    "section": "Experiment Design",
    "text": "Experiment Design\nOne key application considered in this paper is to use a trained ConvGNP to assist an experiment design task of sensor placement where we wish to find the optimal locations to place sensors in order to maximise our knowledge about a region’s environmental variable observations. The setup considered in the paper’s experiment is that we are placing the sensors at once, instead of sequentially (in the case of sequential experiment designs and Bayesian optimisation).\nSome numerical simulations are conducted in the paper to compare the performance of experiment designs when surrogate models are ConvGNP and other GP models. ConvGNP does perform better, but it is also using A LOT more data than the other GP models (for example the contextual data are not used for the other GP models). It would be interesting to see how the performance comparison will change when we allow the other more standard GP models to incorporate more “expert knowledge” summarised from the contextual data.\nAnother thing that ConvGNP could not do - at least the version of the model introduced in the paper - is to sequentially update itself using incremental observations, which can be done by standard GPs. This will be a nice feature that enables sequential experiment designs, which are very relevant in the context of environmental data explorations."
  },
  {
    "objectID": "posts/2024-09-30-ConvGNP/index.html#discussion",
    "href": "posts/2024-09-30-ConvGNP/index.html#discussion",
    "title": "Reading Notes: Environmental sensor placement with convolutional Gaussian neural processes",
    "section": "Discussion",
    "text": "Discussion\nOverall, the paper proposed a deep learning model ConvGNP that can be used to model and predict environmental data and admits natural uncertainty quantifications. The model is extremely suitable in cases where we have an abundance of available training data with varying formats and fidelities. The uncertainty quantifications provided by ConvGNP allow applications to some types of experiment designs, which is great. Further work that extends the model to allow sequential updates and data assimilations would further enhance its attractiveness in the sequential experiment design application."
  }
]